---
title: "Plantilla para el análisis exploratorio unidimensional"
author: 
output:
  html_document: default
  pdf_document: default
---

```{r,include=FALSE}
# install.packages("EnvStats")
library(EnvStats)
library(car)
library(foreign)

```

***

\begin{center}
 \tableofcontents
 \textsc{--}\\
\end{center}



***
\section{Información sobre el Dataset}


El fichero de datos DB_3.sav contiene las variables ZTLIBROP, ZTEJERCI, ZTPOBACT, ZTENERGI, ZPSERVI, ZPAGRICU, ZTMEDICO, ZESPVIDA, ZTMINFAN y ZPOBDENS que respectivamente son los valores para cada país del mundo de:

## Variables

• Número de libros publicados (ZTLIBROP).

• Cociente entre número de individuos en ejército de tierra y población total del estado (ZTEJERCI).

• Cociente entre población activa y total (ZTPOBACT).

• Tasa de consumo energético (ZTENERGI).

• Población del sector servicios (ZPSERVI).

• Población del sector agrícola (ZPAGRICU).

• Tasa de médicos por habitante (ZTMEDICO).

• Esperanza de vida (ZESPVIDA).

• Tasa de mortalidad infantil (ZTMINFAN).

• Densidad de población (ZPOBDENS).

\subsection{Otra información de interés}
  
El dataset contiene un total de 34 instancias con 12 variables, contando con la etiqueta del país al que corresponde las 11 variables mencionadas anteriormente.

\section{Primer acercamiento}

Cargamos los datos a partir del fichero *DB_3.sav*.
```{r,echo=F,include=F}
getwd()

datos_enteros<-read.spss("DB_3.sav", to.data.frame = TRUE)
#Cogemos las variables de interes, es decir, elimino las etiquetas del pais
datos<-datos_enteros[,2:12]
```

\subsection{Primera visualización}

Echamos un primer vistazo a los datos, observando directamente el dataframe en el que vienen, para ver si los datos efectivamente están estandarizados (datos numéricos, continuos, tanto negativos como positivos y entorno al 0), y para comprobar la existencia de *NA*s.
```{r,echo=F}
head(datos)
```

Vemos tanto la existencia de valores perdidos, y que las variables efectivamente están estandarizadas, ya que variables que intuitivamente tomarían valores enteros y relativamente altos como la esperanza de vida o los libros publicados contienen decimales, valores positivos y negativos y todos se encuentran cercanos a 0.

\subsection{Tratamiento de los *NA*}

Vamos a ver si hay, donde, y cuantos *NA* hay en los datos
```{r,echo=F}
cbind(apply(is.na(datos),2,sum),apply(is.na(datos),2,sum)/dim(datos)[1])
```

Vemos que apenas hay variables con datos faltantes, pero una de las variables (*ZTLIBROP*) tiene uno de sus registros faltantes. Como, al ser un único valor perdido en un conjunto de datos con 34 instancias es claro que tenemos menos del 5% de valores perdidos, podemos imputarlo con el valor de la media (ya que es una variable cuantitativa) sin que afecte significamente al resultado del análisis.

```{r,echo=F}
not_available<-function(data,na.rm=F){
  data[is.na(data)]<-mean(data,na.rm=T)
  data
}

datos_pca<-as.data.frame(apply(datos, 2, not_available))
```

Comprobamos ahora que se ha imputado correctamente el valor perdido:

```{r,echo=F}
cbind(apply(is.na(datos_pca),2,sum),apply(is.na(datos_pca),2,sum)/dim(datos_pca)[1])
```

En efecto se ha realizado la imputación de valores perdidos sin ningún problema.

## Recodificación

En este caso no es necesaria.

# Exploración Univariante

## Exploración descriptiva

En este apartado iremos variable por variable obteniendo los resultados de aplicar diferentes medidas descriptivas, clásicas y resistentes, de centralidad, forma y dispersión.

```{r,echo=F}
#Definimos las medidas resistentes
PMC<-function(x){ return((as.double(quantile(x,0.25))+as.double(quantile(x,0.75)))/2)}

trimedia<-function(x){return((median(x)+PMC(x))/2)}

centrimedia<-function(x){
  indices<-(x>quantile(x,0.25)&x<quantile(x,0.75))
  valores<-x[indices]
  return(sum(valores)/length(valores))
}

RIQ<-function(x){return(quantile(x,0.75)-quantile(x,0.25))}

MEDA<-function(x){return(median(abs(x-median(x))))}

CVc<-function(x){return((quantile(x,0.75)-quantile(x,0.25))/(quantile(x,0.75)+quantile(x,0.25)))}

H1<-function(x){return((quantile(x,0.25)+quantile(x,0.75)-2*median(x))/(2*median(x)))}
H2<-function(x){return(median(x)-(quantile(x,0.1)+quantile(x,0.9))/(2))}
H3<-function(x){return(H2(x)/median(x))}

#Creamos una función que aplique todas estas medidas

descriptivo<-function(x){
  
  temp<-rbind(PMC(x),trimedia(x),centrimedia(x))
  rownames(temp)<-c("PMC","Trimedia","Centrimedia")
  centralidad<-list(clasica=list(media=mean(x)),resistente=temp)
  
  temp<-rbind(RIQ(x),MEDA(x),CVc(x))
  rownames(temp)<-c("Rango Inter-Cuartílico","MEDA","CVc")
  dispersion<-list(clasica=list(desviación_típica=sd(x),Coef_varización=sd(x)/mean(x),rango=range(x)),resistente=temp)
  
  temp<-rbind(H1(x),H2(x),H3(x))
  rownames(temp)<-c("Asimetría de Yule","Asimetría de Kelly","Asimetría de Kelly adimensional")
  forma<-list(clasica=list(skewness=skewness(x),kurtosis=kurtosis(x)),resistente=temp)
  cat(names(x))
  return(list(centralidad=centralidad,dispersion=dispersion,forma=forma))
}
```

Aplicamos la función para cada una de las variables:

\newpage

**ZPOBDENS**
```{r,echo=F}
descriptivo(datos_pca[,1])
hist(col="darkblue",datos_pca[,1],main="ZPOBDENS")
```

Las medidas resistentes de centralidad están ligeramente desplazadas hacia la izquierda. Tenemos un valor del *MEDA* inferior al de la desviación típica. En los estimadores de simetría, obtenemos que existe cierta asimetría, y el valor de *kurtosis* indica una acumulación de los datos.

\newpage
**ZMINFAN**

```{r,echo=F}
descriptivo(datos_pca[,2])
hist(col="darkblue",datos_pca[,2],main="ZMINFAN")
```

Lo primero que llama la atención en el histograma es que a prmera vista parecen dos normales pegadas, pero esto puede deberse a que tenemos muy pocos datos en el conjunto a estudiar y sea una normal con una cola larga.

La media se encuentra ligeramente desviada a la izquierda, y de nuevo la MEDA es menor que la desviación típica.

Vemos en el coeficiente de curtosis que la distribución es muy aplanada y asimetría, lo que se corresponde con el histograma.

\newpage

**ZESPVIDA**  

```{r,echo=F}
descriptivo(datos_pca[,3])
hist(col="darkblue",datos_pca[,3],main="ZESPVIDA")
```

Las medidas de centralidad se encuentran desplazadas a la derecha, y la MEDA vuelve a ser menor que la desviación típica. De nuevo mirando el coeficiente de curtosis vemos una distribución bastante aplanada y con asimetría.

\newpage

**ZPOBURB** 

```{r,echo=F}
descriptivo(datos_pca[,4])
hist(col="darkblue",datos_pca[,4],main="ZPOBURB")
```
Esta distribución parece bastante plana mirando el histograma, ningún valor parece predominar demasiado sobre los otros, pero de nuevo se necesitarían más datos para confirmar.
 
La media y medidas de centralidad están muy cercanas a 0 y la curtosis indica que la distribución es bastante plana.


\newpage

**ZTMEDICO** 

```{r,echo=F}
descriptivo(datos_pca[,5])
hist(col="darkblue",datos_pca[,5],main="ZTMEDICO")
```

Las medidas de centralidad se encuentran desplazadas hacia la izquierda y el CVc tiene un valor muy bajo. La curtosis indica que la distribución es plana

También llama la atención como las dos primeras columnas son muy altas y a partir de ellas el resto del histograma se asemeja más a una normal.


\newpage

**ZPAGRICU**  

```{r,echo=F}
descriptivo(datos_pca[,6])
hist(col="darkblue",datos_pca[,6],main="ZPAGRICU")
```

En este caso el histograma se asemeja más al de una normal que en las anteriores variables estudiadas, pese a que se aprecia una asimetría y distribución bastante plana.

Las medidas de centralidad están desviadas ligeramente a la izquierda y la curtosis indica que la distribución es bastante plana.

\newpage

**ZPSERVI** 

```{r,echo=F}
descriptivo(datos_pca[,7])
hist(col="darkblue",datos_pca[,7],main="ZPSERVI")
```

Observamos que las medidas de centralidad están desviadas a la derecha, el MEDA es menor que la desviación típica y la curtosis indica que la distribución es plana.

Además, es claro viendo el histograma que la distribución no se asemeja demasiado a la normal, y es posible que la última columna, al tener frecuencia 1, se trae de un outlier.

\newpage

**ZTLIBROP** 

```{r,echo=F}
descriptivo(datos_pca[,8])
hist(col="darkblue",datos_pca[,8],main="ZTLIBROP")
```

De nuevo ne este caso las medidas de centralidad están desviadas a la izquierda, además se denota una fuerte asimetría en la distribución.

También llama la atención como el rango de esta varuiable es mayor hacia la derecha que el de las demás.

\newpage

**ZTEJERCI** (variable con conclusiones sesgadas)

```{r,echo=F}
descriptivo(datos_pca[,9])
hist(col="darkblue",datos_pca[,9],main="ZTEJERCI")
```



En este caso tenemos unas medidas de centralidad muy desviadas a la izquierda, con una fuerte asimetría y una concentración de datos muy alta en la primera columna.

El rango de esta variable es mucho más amplio que el de todas las demás, y resulta llamativo como los últimos valores de la derecha no tienen una frecuencia alta, haciendo sospechar de que sean outliers.

\newpage

**ZTPOBACT** 

```{r,echo=F}
descriptivo(datos_pca[,10])
hist(col="darkblue",datos_pca[,10],main="ZTPOBACT")
```

Esta distribución se parece más a una normal que algunas de las estudiadas anteriormente, está más centrada (sus medidas de centralidad son más cercanas a 0) y su curtosis es baja, lo que indica una distribución aplanada.

Mirando el histograma apreciamos algunos valores cerca de -2 que pueden parecer outliers por su separación con el resto de los valores representados.

\newpage

**ZTENERGI**  

```{r,echo=F}
descriptivo(datos_pca[,11])
hist(col="darkblue",datos_pca[,11],main="ZTENERGI")
```

Al igual que en uno de los casos anteriores tenemos las medidas de centralidad desviadas a la izquierda, una curtosis bastante alta y un rango de valores amplio, con algunos separados de los demás en los extremos que parecen outliers.

**NOTAR**: el hecho de que algunas de las variables estén desplazadas hacia la derecha, o que los outliers sean en esta dirección, es debido a que estas son estandarizaciones de variables positivas, en una variable positiva el valor mas extremo inferior como mucho es $0$.

Las que si tienen extensión hacia la izquierda, es debido a que no hay un gran porcentaje de la población que se acerque al extremo inferior, entonces el $0$ realmente si acaba siendo un valor "extremo" para estas variables.

También notar que el *CVc* toma valores bastante "sin sentido" debido a que esta medida no tiene mucho sentido en variables que toman valores positivos y negativos, en el caso de la variable 15 ese valor es devido a que $Q_1 \approx -Q_3$

## Exploración Gráfica

Procedemos con los diagramas de cajas y bigotes, para una detección primaria de outliers univariantes.

```{r,echo=F}
colfunc<-colorRampPalette(c("darkblue","lightblue"))
boxplot(datos_pca,
        xlab=NULL,
        ylab="Nombre-y",
        col=colfunc(15),
        las=2)
```

Se puede observar que la mayoría de gráficos se asemejan en cierto modo a una normal, con los 5 primeros estando ligeramente desplazados, los 15 14 y  9 10 siendo los que mas normales aparentan ser, y con 13 y 12 (*zpoblac* y *zdensidad*) con una gran concentración al 0, y una gran cantidad de outliers en la cola superior

(El tratamiento que tendremos con estos valores outliers será el mismo que en la práctica anterior, aunque en lo personal, no creo que sea buena idea eliminar los outliers de las variables *zpoblac* y *zdensidad*; me explico: 

Cuando consideramos que un valor es un outlier, es por que suponemos que no es representativo de la población para el tamaño de muestra que tenemos; en este caso, los outliers los estamos considerando en base a un diagrama boxplot, este indica valores outliers basándose en la hipótesis de estar en una distribución normal, en el caso de *zpoblac* y *zdensidad*, es claro que no proviene de una normal, luego este "análisis outlier" no es valido **directamente a estas variables**, para el resto se podría "pasar la mano" o hacer contrastes de normalidad.)

A continuación vamos a observar (de nuevo) la forma de las distribuciones de las variables mediante sus histogramas

```{r,echo=F}
par(mar=c(1,1,1,1))
par(mfrow=c(3,5))
invisible(apply(datos_pca, 2,function(x){hist(x,main=NULL,col="darkblue",xlab=NULL,ylab=NULL)}))

```

Observamos que realmente pocas de las variables realmente se podrían considerar normales (la 1 y 7 por los pelos, la 6, 9, 14 y 15), pero como no son casos tan extremos como 12 y 13, se eliminarán los outliers de todas menos de estas dos.

### Tratamiento de outliers

Los valores outlier comentados anteriormente (según si el diagrama boxplot los consideraba outliers o no, y contando con las excepciones comentadas) serán intercambiados por la media. 

```{r,echo=F}
outlier<-function(data,na.rm=T){
  H<-1.5*IQR(data)
  
  if(any(data<=(quantile(data,0.25,na.rm = T)-H))){
    data[data<=quantile(data,0.25,na.rm = T)-H]<-NA
    data[is.na(data)]<-mean(data,na.rm=T)
    data<-outlier(data)}
  
  if(any(data>=(quantile(data,0.75, na.rm = T)+H))){
    data[data>=quantile(data,0.75, na.rm = T)+H]<-NA
    data[is.na(data)]<-mean(data,na.rm=T)
    data<-outlier(data)
  }
  return(data)
}

datos_pca[,-12:-13]<-apply(datos_pca[,-12:-13], 2, outlier)
```

Una vez tratados los outliers, vemos de nuevo los gráficos boxplot.

```{r,echo=F}
boxplot(datos_pca,
        xlab=NULL,
        ylab="Nombre-y",
        col=colfunc(15),
        las=2)
```
 
Efectivamente, hemos perdido dichos valores anómalos.

\newpage

### Normalidad

Para poder aplicar ciertas técnicas estadísticas, es importante saber si estamos tratando con variables normales, para ello usaremos el método gráfico *qq-plot*.

```{r,echo=F}
par(mar=c(1,1,1,1))
par(mfrow=c(3,5))
invisible(apply(datos_pca, 2, function(x){
  qqnorm(x,main=NULL)
  abline(a=0,b=1,col="red")
}))
```

Vemos como las variables que mas se acercan a la normalidad son la 4, 6, la 10, la 14 y la 15. No tan cerca están las variables 1, 2, 3, 5, 7, 8, 11, y con desviaciones totales encontramos las variables 12 y 13 (estas desviaciones pueden estar debidas a sus numerosos valores outliers no tratados). 

En este caso no tomaremos medidas para obtener normalidad en los datos.

\newpage


### Homocedasticidad

La homocedasticidad se debe comparar dentro de una misma variable, para dos o mas grupos diferenciados; en el caso de este dataset, podemos comprobar si existe homocedasticidad entre los grupos definidos por la religión Católica y Musulmana (los dos grupos mas frecuentes, puesto que de los otros hay tan pocos que podrían dar conclusiones equivocadas) que profesa cada país.

```{r,echo=F}
ind<-which(datos_enteros$relig=="Musulma."|datos_enteros$relig=="Católica")
factores<-datos_enteros$relig[ind]
#Como se han eliminado los valores outlier, usamos con centro la media en vez de la mediana
#H0:homocedasticidad
apply(datos_pca[ind,], 2, function(x){
  if(leveneTest(x,as.factor(factores),center=mean)$"Pr(>F)"[1]>0.05){
    "Existe homocedasticidad entre los grupos"
  }
  else{"No existe homocedasticidad entre los grupos"}
  })
```

Vemos como para la mayoría de variables, seccionando los paises según religión, se tiene la misma varianza. Donde no se cumple es para el índice de **alfabetización**, **Calorías**, **Log-PIB**, **Densidad de población** y **Log-densidad de población**  (podría deberse a que muchos paises musulmanes se encuentran en el continente Africano, donde de por si muchas de esas variables son significativamente diferentes al resto del mundo.). 

\newpage

## Exploración Descriptiva
    
A continuación vamos a sacar los principales estadísticos descriptivos ahora que tenemos los datos transformados.

**Originales**
```{r,echo=F}
summary(datos)
```

**Tratados**
```{r,echo=F}
summary(datos_pca)
```




















 



